[{"id":0,"href":"/posts/glossary/","title":"Glossary","parent":"Posts","content":"AD - Active Directory - local database that contains all information.\nADSI - Active Directory Service Interfaces\nAM - Access Management\nAPI - Application Programming Interface\nAttribute - specific criteria provided by the managed systems to describe the expected assignments for an identity.\nBastion - element used like an intermediary so that an administrator connects to bastion when they need sensitive access. It allows action tracking.\nClaim - value for a given identity such as email, last name, groups, etc.\nCN - Common Name\nConnection - part of a connector, contains a package and its settings.\nConnector - container that connects the USERCUBE server to the external system to get information. It is made of one or several connection(s). It is used to export/import data as CSV source files for USERCUBE synchronization process and to fulfill entitlement assignments to the target data.\nDN - Distinguish Name\nCSV files - files containing data tables.\nDirectory - connector containing the organized entities.\nEntity association - link between entity types. It can be monovalued or multivalued (ForeignKey). It is monovalued if it is a 1-to-1 or many-to-1 association. Then the target column index must be between 128 and 138. It is multivalued if it is a many-to-many or a 1-to-many association. Then there is no target column index. In the client-commands association, there can be several commands for only one client, thus client is monovalued while commands is multivalued.\nEntity type - conceptual data model of a business object. Defines the shape (and not the intent) of the associated resource by defining a set of properties and relationships with other entity types.\nHash - unique way to store a password without knowing the password.\nIAG - Identity Access Governance\nIAM - Identity Access Management\nIdentity - managed system user. Identities are modeled using entity types and organized in a connector called directory. It can be a person or an application or a device. If you know it is a person, it still can be an employee, a provider, a partner, a customer, etc.\nIGA - Identity Governance and Administration\nJust in time provisioning - sensitive permisisons are allowed only on restricted periods of time, according to practical needs.\nKey properties - properties that identify an entity in the USERCUBE server.\nLDAP - Lightweight Directory Access Protocol - directory with a key/value database and organized with a tree hierarchy.\nMapping key - property that acts as the unique identifier for an entity in the external system.\nMFA - MultiFactor Authentication - authentication with password AND phone number for example.\nNavigation - said of a property when it stores link(s) between elements as identifiers.\nObjectGUID - non-modifiable identifier.\nOn-boarding - creation of a new account for a new employee.\nOU - Organizational Unit\nPackage - technology used by a connector to get the needed information.\nPAM - Privileged Access Management - avoids attacks to sensitive accounts thanks to Just-In-Time provisioning and a bastion based system.\nPolicy - set of rules to assign entitlements to identites.\nRBAC - Role Based Access Control\nReference data - data describing the whole organization\u0026rsquo;s structure, including for example contractors that are not part of the HR data.\nRole model - set of objects containing a model of the entitlement landscape for all managed systems and every rule that Usercube must enforce.\nSalt - random string appended to the password hash to hide identical passwords.\nScalar - said of a property when it only stores data.\nServer - kind of black box that reads the client\u0026rsquo;s http requests.\nSynchronization - snapshot of data (HR data for ex) copied in USERCUBE database at t time.\nToken - digitally signed list of claims.\nUI - User Interface\nUser record - different from the user that shows the identity of an user, the user record contains the information that can change according to the user\u0026rsquo;s job inside the organization.\n"},{"id":1,"href":"/posts/IGA/","title":"IGA and USERCUBE by Nicolas","parent":"Posts","content":"IAM / IAG    IGA -Identity Governance and Administration- is a combination of IAM and IAG.\nIAM -Identity Access Management- allows identities to have the right rights at the right time for the right reasons.\nIAG -Identity Access Governance- allows actors to follow the developments concerning identities and user access, and monitor compliance.\nGartner is a form that means to give expert guidance and tools to enable smarter and faster decisions and stronger performance on an organization\u0026rsquo;s most critical priorities. It especially publishes a kind of comparison quadrant for IGA firms.\nIGA tools are meant to give only the needed permissions, so you have to know all the people, all the permissions, know what is relevant, track and plan changes.\nUSERCUBE    USERCUBE is a powerful tool for IGA automation. It works through three major steps :\n Synchronization - data import ; Calculation - computation of entitlement assignments / conformity check ; Provisioning - assignments fulfillment.  USERCUBE\u0026rsquo;s major stake is to create and automate roles associated to resources, so that an user can automatically get the right accounts and permissions according to their job. USERCUBE especially shows its skills while working at a large scale in user population.\nIAM HISTORY    GEN 1    Principle - simple file with a list of users and password hashes - simple file with a list of groups and members - simple data model.\nn users for n groups.\nPros: simplicity.\nCons: limited number of resources / not centralized / no delegated administration / access to hash.\nGEN 2    Principle - LDAP directories.\nn users for n groups with n organizational units.\nPros: good read performance / central repository (shared between several applications) / delegated administration. Cons: limited integration with servers.\nGEN 3    Principle - AD : Windows server LDAP directory with Microsoft extensions - cryptography with public and private keys - single sign-on (access to several services through a single authentication).\nn users for n global groups (business role like services or sites) for n local groups (application: set of resources always used together) for n resources (object to protect like a file share or an application).\nPros: replication / RBAC / office automation like printers or emails.\nCons: not opened to Internet.\nGEN 4    Principle - Identity federation extends AD to multiple authentication sources and to Internet. Ex: FranceConnect.\nIt works with claims and tokens, identity providers that allow authentication and return a token describing the idntity, and applications that use tokens from trusted identity providers to compute the user\u0026rsquo;s permissions.\nPros: single sign-on / password only by the identity provider / compatible with On-Premises (local) AND internet services.\nCons: simple access control model based on claims.\nGEN 5    Principle - Access Management (AM). Ex: Azure AD / SaaS identity provisioning.\nPros: multifactor authentication (MFA) / conditional access according to hours or locations or whether the PC is safe / password less authentication.\nCons: weak user administration / simple access model based on an user/claim system.\nPAM - Privileged Access Management    PAM avoids attacks to sensitive accounts thanks to Just-In-Time provisioning and a bastion based system. A bastion is an element used like an intermediary so that an administrator connects to bastion when they need sensitive access. It allows action tracking. Just-in-time provisioning allows to give sensitive permisisons only on restricted periods of time, according to practical needs.\n"},{"id":2,"href":"/posts/Introduction-guide/","title":"Introduction Guide","parent":"Posts","content":"Overview    Usercube is a three-aim solution for IGA.\nAim 1 - Manage Identity Lifecycle    Usercube builds a reliable directory of identities and manages their evolution. An identity can be an employee, contractor, partner, customer, object, software, robot.\nAim 2 - Provide Entitlement Management    Usercube creates an exhaustive and reliable catalog of the entitlements available in the managed systems and fulfills the right assignments to the right users. It uses a policy to describe the expected assignments for every identity based on attributes provided by the organization\u0026rsquo;s reference data. These assignments, and any changes (on-boarding/off-boarding/position change) can be automated by roles.\nAim 3 - Governance    Usercube makes sure that the existing assignments of entitlement comply to the policy. Non conforming assignments are pointed out thanks to synchronization.\nThree-step Principle     Gather organizational reference data and digital identities from managed systems and authoritative sources. Compute entitlement assignments from organizational reference data and the role model. Fulfill assignments to managed systems.  Note that any change performed by Usercube to the managed system comes as an input for assignments computation.\nTwo-tier Architecture     The Usercube server operates the assignment computation, stores the organizational reference data and serves a web UI. The Usercube agent operates data exchanges with the managed systems. It is isolated from the server to ensure the server has no direct access to the managed systems.  The Usercube server can be installed either on-premises, meaning on an isolated network within the organization, or dwell in the cloud and be provided as a service.\nFundamentals    Resource and Reference Data    Resources refer to the data from the managed systems that is read and written by Usercube. It can be an AD account, an HR system entry, an employee\u0026rsquo;s digital identity, etc.\nThe unified resources repository contains the resources' organization, all the data needed to perform assignment computation. This includes a copy of the managed systems' data and data input directly into Usercube. It is called \u0026ldquo;unified\u0026rdquo; because this repository\u0026rsquo;s data is organized without considering the source within the managed system.\nThis resources repository is structured by a customizable entity-relationship model: each resource is assigned an entity type. Entity types are gathered into a connector.\nIn order to shape the managed system\u0026rsquo;s reference data, Usercube provides entity types, relationships and a set of mapping rules.\nReference data is a middleman between the source and target managed systems. This yields several advantages:\n unreliable data sources do not harm the IGA project; identities that do not exist in the managed system as-is can still be used; the number of assignment rules to be manually written is considerably reduced.  The identity changes are in position changes.\nThe resource lifecycle includes:\n Upward data synchronization or sync up copies data from the managed systems and authoritative sources to the resources repository. Managed systems are linked to Usercube by connectors. Manual input is used for data with no reliable authoritative source and that rarely change. Workflows describe an organization\u0026rsquo;s process and allow the user to create approval steps involving different actors. The assignment policy describes the way entitlements must be assigned to identities by Usercube through a configurable set of rules.  Role Model    The aim of the role model is to enable Usercube to express entitlement assignments from various authorization mechanisms in different managed systems with the same languague: roles. Single and composite roles materialize entitlements, while scalar and navigation rules in collaboration with resource types materialize and automate access to certain data or physical locations by opening digital locks.\nResources are gathered into groups that share the same concerns from the security officer\u0026rsquo;s point of view. These groups are called resource types and are assigned to resources by classification rules.\nThus the role model contains instructions to fulfill the correct values in the managed systems in order to materialize entitlement assignments. A source resource owns a target resource (an identity owns an account, HR system entry owns an identity). Resource types describe how a type of resources must be fulfilled. Usercube\u0026rsquo;s engine can find an existing target for a source thanks to correlation rules.\nEnforcing the Assignment Policy    Let\u0026rsquo;s zoom in on the three-step principle:\n Gather organizational reference data through synchronization ie., build existing assignments lists. Compute entitlement assignments ie., check conformity between the managed systems and the assignment policy. Fulfill assignments ie., fix non-conforming resource values and assignments.  A few algorithms run the Usercube\u0026rsquo;s engine. Among them, Evaluate Policy reads the role model rules and resource values to compute entitlement assignments (set of assigned roles to resources).\nA non-conforming value can mean either that the role model still needs some tuning to match the organization\u0026rsquo;s will, or that it does match and real security issues are detected. It means that a user has been assigned an entitlement that they don\u0026rsquo;t need, or they are missing an entitlement that they need.\nA confirmed non-conforming value becomes an exception that is then integrated to the assignment policy.\nUsercube Patterns - Example    Simple example    Let\u0026rsquo;s consider an organization using an HR system and an Active Directory. The aim is to ensure that the main system\u0026rsquo;s content (HR) is pushed to the secondary systems (AD).\nConfiguration: model the organizational reference data and the identity model with entity types and relationships; write the role model to map HR data to AD users.\nUsercube process: synchronize HR and AD; configure the role model to map HR data to AD users and compute their groups memberships; review and update non-conforming values.\nA few contraints more    Let\u0026rsquo;s say the previous organization:\n employs contractors who all need AD accounts; uses a telephony system for some employees and contractors; uses two buildings so two distinct security systems.  As there is no contractors database in the managed systems, we have to input some contractor\u0026rsquo;s information by hand. Plus, there are now three managed authoritative sources: HR system; contractor\u0026rsquo;s information; telephony system. And there are three managed security systems: one AD and two buildings.\nThe first version of the project connects the HR system to the AD. The limitations are as follows:\n digital identities are split into several systems; the amount of rules to write grows quadratically; contractor\u0026rsquo;s information cannot be stored in the HR system that would be overwritten by synchronization.  The solution is to create a new set of entity types to model all actors. The new worker resource consolidates all the authoritative sources data into one place. Thus, assignments are computed and fulfilled from the worker resources data. The advantages are listed below:\n the workerresources are not a direct copy of the HR system and can thus be changed without being overwritten by synchronization; the number of rules to write switches to a linear complexity;   the AD is used as a source and a target; the worker resources can take the shape you choose to fit the organization best.  Temporary assignments    Temporary assignments can be managed through positions that can change during an identity\u0026rsquo;s lifecycle. An identity is modeled as shown on the picture below:\nArchitecture overview    The solution is composed of the server and its functions, the database, the agent and its functions.\nThe database stores all the data needed by Usercube, including for example the applicative configuration, resources repository, assignment policy, computed assignments.\nThe server provides the APIs used by the UI. It uses server functions to perform module-specific computations like data loading, assignment policy enforcement, assignment review notifications.\nThe agent provides APIs to trigger the agent functions that interact with the managed systems. With credentials, they are necessary and sufficient to read/write data from/to the managed systems.\nThe Usercube\u0026rsquo;s architecture considers a few security concerns:\n credentials can be accessed only by agent functions; network communications only travel from the agent to the server; there can be several agents installed to meet network and security constraints; the APIs can be configured to be accessible only by some chosen users;  These security services for isolation and one-way control allow the Usercube server to be used as a service hosted in the cloud (SaaS). It makes setup and maintenance easier by limiting them to the agent side without any security trade-offs.\nConfiguring Usercube    The Usercube configuration is stored in the database so the server and its functions fetch their settings from the database.\nThe configuration can be edited either by the UI, or exported to XML files and then reimported from these files to the database.\n"},{"id":3,"href":"/posts/Further-reading/","title":"Further Reading","parent":"Posts","content":""},{"id":4,"href":"/posts/tutorial/","title":"Tutorial - Training steps","parent":"Posts","content":"Installation of the USERCUBE Demo Latest Version    In order to use USERCUBE on your local device, you need to realise an installation on premise. You follow the steps below:\n You first look for the latest version of the USERCUBE server on the Pipelines page. You download the three bottom folders : Runtime, SDK and SQL. On your computer C:\\UsercubeDemo, you delete everything except Sources and Runtime folders. You rename Runtime into RuntimeOld. You extract the content of your previously downloaded folders into UsercubeDemo. Note that you keep the whole Runtime folder, while you take only the content of SDK and SQL folders and you put the content of Usercube.Demo into C:\\UsercubeDemo and you delete the empty folder. You copy the appsettings and appsettings.agent json files from RuntimeOld into Runtime. You copy only appsettings into C:\\UsercubeDemo and delete appsettings.encrypted.agent. You copy the Usercube.pfx from Runtime into C:\\UsercubeDemo. You open the Jobs XML file in C:\\UsercubeDemo\\Conf\\Jobs to add two lines as described below.  You add:\n\u0026lt;NotUsed ConnectorIdentifier=\u0026#34;AzureAD\u0026#34;/\u0026gt; \u0026lt;NotUsed ConnectorIdentifier=\u0026#34;LDAP\u0026#34;/\u0026gt; Into the existing code to finally have:\n\u0026lt;CreateInitializationJob ... \u0026gt; ... \u0026lt;NotUsed ConnectorIdentifier=\u0026#34;SharedFolder\u0026#34;/\u0026gt; \u0026lt;NotUsed ConnectorIdentifier=\u0026#34;AzureAD\u0026#34;/\u0026gt; \u0026lt;NotUsed ConnectorIdentifier=\u0026#34;LDAP\u0026#34;/\u0026gt; \u0026lt;NoConnectorSynchronization ConnectorIdentifier=\u0026#34;Directory\u0026#34;/\u0026gt; ... \u0026lt;/CreateInitializationJob\u0026gt;  Finally in C:\\UsercubeDemo\\Scripts you run the command: .\\Install-OnPremise.ps1  The latest version of the USERCUBE server is installed and runs.\nFirst Run    You can run USERCUBE for the first time by importing minimum configuration, launching the USERCUBE server and connecting with the default admin account.\nFirst you need to place your prompt in your Runtime folder, here : cd C:\\UsercubeTraining\\Runtime\nTo import the configuration : .\\Usercube-Deploy-Configuration.exe --database-connection-string \u0026quot;data source=.; Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;\u0026quot; --configuration-directory \u0026quot;C:\\UsercubeTraining\\Conf\u0026quot; -e -c\nTo launch the server : .\\Usercube-Server.exe\nTo open the server, open a web browser with the following URL : http://localhost:5000\nTo connect, the login is Admin and the password secret.\nHR Synchronization    AIM : retrieve HR data.\nWe generate configuration to create the file HR Connector.xml in order to store the paths to our sources and information to create entities. We add display names for HR entities and departments. We export HR sources from CSV files. We prepare synchronization (while server must be running) and we synchronize in order to insert all HR resources in the database. We compute the expressions. We create menu items to see the HR resources on the server.\nTo generate configuration : .\\Usercube-Generate-Configuration.exe --connector-description 'C:\\UsercubeTraining\\Generator\\HR Generator.xml' -g 'C:\\UsercubeTraining\\HR Connector.xml' --keep-all-columns -c 'HR'\nTo export HR_Person sources : .\\Usercube-Export-Csv.exe --raw-files-path \u0026quot;C:\\UsercubeTraining\\Sources\\HR_Person.csv\u0026quot; --separator \u0026quot;,\u0026quot; --output-path \u0026quot;C:\\UsercubeTraining\\Temp\\ExportOutput\u0026quot; --connection-identifier \u0026quot;HRPerson\u0026quot; --ignore-cookies\nTo export HR_Department sources : .\\Usercube-Export-Csv.exe --raw-files-path \u0026quot;C:\\UsercubeTraining\\Sources\\HR_Department.csv\u0026quot; --separator \u0026quot;,\u0026quot; --output-path \u0026quot;C:\\UsercubeTraining\\Temp\\ExportOutput\u0026quot; --connection-identifier \u0026quot;HRDepartment\u0026quot; --ignore-cookies\nTo prepare synchronization : .\\Usercube-Prepare-Synchronization.exe --connector 'HR' --synchronization-mode Initial --sources-directory \u0026quot;C:\\UsercubeTraining\\Temp\\ExportOutput\u0026quot; --working-directory \u0026quot;C:\\UsercubeTraining\\Work\\Collect\u0026quot; --api-url 'http://localhost:5000' --api-client-id 'Job' --api-secret 'secret’\nTo synchronize : .\\Usercube-Synchronize.exe --database-connection-string 'data source=.\\SQLEXPRESS;Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;' --connector 'HR' --input-path 'C:\\UsercubeTraining\\Work\\Synchronization'\nTo compute expressions : .\\Usercube-Update-EntityPropertyExpressions.exe --database-connection-string 'data source=.;Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;' -a\nReference Data and Identities (Modeling and Loading)    Reference data is the data describing the organization\u0026rsquo;s structure, including for example contractors that are not part of the HR data we retrieved. We want to build a reference data model through Entity Types organized in a connector called Directory.\nAIM : create the Directory model and fulfill it with the HR data previously synchronized in USERCUBE.\nWe generate configuration to create the file Directory Connector.xml in order to store the paths to our sources and information to create entities. We modify the connector file according to our needs. We create the associations we want (user and user record, department parent and child, department and supervisor, etc.). We add display names for our entities. We can create new entities through an entity type, internal, external and UI resources. We create a Directory Navigation.xml file to manage the interface buttons. We create the dimensions, context rules and record sections that are key criterias for future assignment rules. Then we create a resource type that links a source object to a target object through scalar, query and correlation rules. We fulfill the directory connector by adding connections and mapping of the resource types.\nIn order to fulfill the directory, you need to follow the process : pre-calculation / computation / creation of JSON files with information / insertion in the database. Plus, this process must run three times : the first time to create the entities, the second time to create the links between these entities and check the entities, the third time to check the links.\nIn practice, we deploy the configuration and compute the correlation keys and the role model. To generate the JSON files for the provisioning orders, we deploy the configuration again then we generate these orders. Then we insert the resources in the database. Then we create a synchronization job and deploy the configuration once again. Finally we launch this fulfillment job twice.\nTo compute correlation keys : .\\Usercube-Compute-CorrelationKeys.exe -a --database-connection-string 'data source=.;Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;'\nTo compute role model : .\\Usercube-Compute-RoleModel.exe --database-connection-string 'data source=.;Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;' --entitytype-list 'HR_Person' 'HR_Department’\nTo generate provisioning orders : .\\Usercube-Generate-ProvisioningOrders.exe --database-connection-string 'data source=.\\;Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;' --connector 'Directory' -f --mail-from 'no-reply@acme.com' --mail-use-pickup-directory --mail-pickup-directory 'C:\\UsercubeTraining\\Temp\\Mails' --server 'http:/localhost:5000' --output-path 'C:\\UsercubeTraining\\Work\\ProvisioningOrders’\nTo insert resources : .\\Usercube-Fulfill-InternalResources.exe --database-connection-string 'data source=.;Database=UsercubeV5training;Integrated Security=SSPI;Min Pool Size=10;' --connector 'Directory' --input-path 'C:\\UsercubeTraining\\Work\\ProvisioningOrders’\nActive Directory Synchronization    AIM : retrieve the Active Directory content.\nWe start by extracting the AD resources to generate the configuration. We generate the connector with source files and adapt the connections, associations, mapping and navigation according to what we need. We modify the appsettings.agent.json file with the open id, password settings and connections. We create an AD synchronization job and finally launch it on the interface.\nTo extract data : .\\Usercube-Export-ActiveDirectory.exe --server “localhost:9400” --sync-dn 'DC=acme,DC=internal' --sync-filter '(objectclass=*)' --auth-type 'Basic' --login 'CN=administrator,DC=acme,DC=internal' --password 'Usercube@2018' --sync-attributes 'accountExpires c cn dn employeeNumber givenName l mail name:rdn objectCategory objectGuid:guid objectSid:sid ou pwdLastSet:1601date rdn sAMAccountName sn telephoneNumber userAccountControl userPrincipalName parentdn employeeID member:link manager:link' --ignore-cookies --output-path 'C:\\UsercubeTraining\\Sources' --connection-identifier 'ad' --cookie-path 'C:\\UsercubeTraining\\Work\\ExportCookies'\nTo generate AD connector : .\\Usercube-Generate-Configuration.exe --connector-description 'C:\\UsercubeTraining\\Generator\\AD Generator.xml' -g 'C:\\UsercubeTraining\\AD Connector.xml' --keep-all-columns -c 'AD'\nActive Directory Provisioning    AIM : fulfill changes to the Active Directory, that is to say create fine-grained entitlements for accounts and their data, correlation between owners and accounts, and manage on-boarding (a new account for a new employee).\nWe create a Directory User Role Model AD.xmlfile, add the category AD and the resource type to link it to the user directory, with rules, mapping and password settings. In AD Jobs.xml we add a provisioning task. We deploy the configuration and launch the AD synchronization job.\nIf we want to add a new employee and thus a new AD account, we need to use an administrator profile and add new rights in Profile Administrator.xml. With the right configuration files, we deploy the configuration, launch the server and create the database views. Then the creation of this new account can be done through the USERCUBE interface (new employee and AD synchronization).\nTo create database views : .\\Usercube-Create-DatabaseViews.exe --api-url http://localhost:5000 --api-client-id \u0026quot;Job\u0026quot; --api-secret \u0026quot;secret\u0026quot;\nEntitlement Management    AIM : build a role model to manage entitlements.\nThe roles and rules are created via the USERCUBE interface. We first create SharePoint groups. We also create single roles and the rules that assign a group for a user. We can assign manually and automatically the roles for a resource, review it if we want to and check reconciliation.\n"},{"id":5,"href":"/posts/Connectors/","title":"Connectors","parent":"Posts","content":"How to Create Connectors from the User Interface    On the Home page of the USERCUBE server, there is a Connectors button.\nYou click on this button and you see all existing connectors. To create a new one, you click on + New.\nYou fill the information. In this example, we want to call our connector AD_TEST. We give the same name in English(US). We choose a local agent. You click on Create and get on the connector page.\nThe next step consists in creating a connection. So you click on + Add.\nYou select a package and fill the associated information on the right-hand side. Here we want to create an active directory and we give it the same name as the connector, which is AD_TEST. The rest of the package information is specified in the appsettings.agent.json file.\nYou click on Check Connection to chek if the path is correct. You click on Refresh schema and you Create and close.\nYou go back on the connector\u0026rsquo;s page and create an entity type by filling the identifier and name.\nA few lines below, you click on Properties. There are two types of properties: the scalar and the navigation properties.\nYou start by choosing a Source in the dropdown list. This source contains the properties that already exist in the external system.\nThen you create your Scalar Properties. You give them the name, format and translation that you want to see displayed on the user interface. On the right-hand side you select the external system\u0026rsquo;s column that your property is extracted from. You can also select the format that the property takes when it is fulfilled from the USERCUBE server to the external system.\nYou choose among your properties a Mapping Key that is used as a unique identifier in the external system. You also choose Key Properties that point out the essential properties that will identify your entity type in USERCUBE.\nYou create your Navigation Propertiesthe same way you created the scalar properties. You give your two linked properties the name and translation that you want to see displayed on the user interface. You notify the corresponding entity type and the cardinality. Again, on the right-hand side you select the external system\u0026rsquo;s columns that your properties are extracted from and their source.\nEvery time you modify something in the connector, a green warning appears saying that you should reload the schema to consider the changes. You simply click on it.\nThe next thing you need to create to have a complete connector is a Resource Type that contains rules in order to classify the properties.\nYou click on + Add.\nYou fill the resource type\u0026rsquo;s information. The Source Entity Type is the entity type in the external system that you want to correlate to the Target Entity Type that is the entity type in the Usercube server.\nOn the right-hand side, you fill the settings.\nYou can then create correlation rules to link a Source Object, resource from the external system, to a Target Object, resource you created in USERCUBE. Then you adjust the confidence rate.\nYou can also use C# expressions to correlate the properties like in the example below.\nYou can then create classification rules to classify your properties.\nYou can also create other kinds of rules by clicking on More Rules.\nThis button leads to the Access Rules page. You click on + New to create a new rule.\nFor a Scalar rule:\nFor a Query rule:\nFor a Resource type rule:\n"},{"id":6,"href":"/posts/hugo/","title":"Hugo","parent":"Posts","content":"Hugo is a software that helps write in Go language in order to build blogs and static sites and put them online. It is a software that combines files to turn them into HTML, CSS and JavaScript files.\nWith Hugo you write in Markdown, which is a markup language easier to use than HTML.\nThese are the steps to build a new website:\n You create a folder to store your future website. You place your prompt in this folder and command hugo new site NAME. You download the theme you want to use and rename the folder THEME. You open the file config.tomland change it into theme=\u0026quot;THEME\u0026quot;. In order to see your blog, you command : hugo server -D and if your website contains drafts that you want to see, you add buildrafts. In order to create a post, you command : hugo new FOLDER/POST_NAME.md.  These are the steps to open and modify your website:\n You start by opening your text editor such as VS Code or Typora. You place the prompt into the folder containing the pack of files you want to modify. You enter this command : hugo server -D with or without buildrafts.  Here are a few tips to use Hugo to modify your website:\n To insert an image \u0026ndash;\u0026gt; ![alt](IMAGE-NAME.png) To insert a link from the Internet \u0026ndash;\u0026gt; [appearing text] (www.blabla) To insert a link from the doc \u0026ndash;\u0026gt; [appearing text](/) To give only a summary on the home page for a post \u0026ndash;\u0026gt; summary:TITLEin the front or \u0026lt; !--more--\u0026gt; (space-free) in the back. To create a menu, you modify config.md.  These are the steps to finally publish your website:\n In Github you create a new repository and click on Upload. In the prompt you command hugo --minifyto create a static public folder. You upload all the files inside it into Github.  "},{"id":7,"href":"/posts/html/","title":"Html","parent":"Posts","content":""},{"id":8,"href":"/posts/Tasks/","title":"Tasks","parent":"Posts","content":"How to process tasks    There are three types of tasks for the USERCUBE documentation: bugs ; features ; studies.\nWhen you start working on a ticket, you first work on dev.azure:\n You change the task state to Active. You create a branch called doc/XXXXX_aaaaaaa where XXXXX is the task number and aaaaaaa is the explicit name you decide to give it.  Then you open GitExtensions:\n You click on Pull in order to get all the updates. You find your branch and right-click on it to realise Checkout.  Then you can open your text editor like VS Code or Typora and resolve your problem(s).\nYou come back to GitExtensions:\n You Commit your changes to the server. A new window opens showing your changes. On the left, you double-click on the line you are interested in. In the bottom frame, you type doc #XXXXX aaaaaaa followed by further explanation so that the future reader of this ticket can quickly understand what has been done here. Then you click on Commit. Finally you click on Push.  Once again you open dev.azure:\n You create a Pull request. You change the task state to Review.  At this point, you wait for your task\u0026rsquo;s approval by the reviewer(s). If they leave comments, you can work on it again:\n You correct what you need to on your text editor. You commit and push once more on GitExtensions to update the pull request.  When they approve the pull request, change the state to QA and wait for quality service approval. You repeat the two previous steps.\nThen you finally go to dev.azure and click on Complete.\nAnother way when working with an external person    Sometimes you give away some tasks to people who are not used to GitExtension and DevOps. When they finish their task(s), you can follow the following steps:\nOn DevOps you look for the corresponding ticket or you create one if needed.\nOn GitExtension:\n You start by clicking on Pull to get the latest changes. You right-click on Master on the left-hand side to choose Checkout in order to place your future work on this branch. Then you create a branch either in Commands \u0026gt; Create a branch or with a right-click on Master and Create a branch. You name it according to the ticket. By clicking on Stash you put your last changes aside and your commit number comes back to zero. You right-click on the branch you want to modify and Checkout. You click on Stash pop to \u0026ldquo;get the changes back\u0026rdquo;. You Commit your changes and Push as usual.  Sometimes, there can be conflicts when you try to merge your changes to a file that has been changed by someone else in the meantime you were working on it.\nAt this point, you do not try to solve the conflicts on GitExtension and you open Visual Studio Code:\n You use Source Control on the left-hand side to open the conflicted file(s) pointed out by an exclamation point. The conflicts are highlighted with green and blue and you just choose the current or incoming change. Once you go through the whole file, you click on the + sign next to the name of the file to stage the change. Then you can Commit as usual.  You finalise as usual by pushing the change and creating a pull request.\nNote that the purpose of Pop/Stash is to put your commits aside while you want to work on a different branch.\nAutomatically generated pages    In the Data model section, the pages are generated automatically. They use the following type of command: {({\u0026lt; includeDataModelStatic \u0026quot;folder/File.md\u0026quot; \u0026gt;})} (without the parenthesis) which copies and pastes in its place the content of the file File.mdfrom the references/Data_Model-static/folder folder.\nOnce you modified something in this type of files, you need to regenerate the documentation. It is usually done using Visual Studio. When this software is no installed on your computer, you can command: dotnet build -c Debug C:\\Projects\\UsercubeV5\\Z.GenerateDocumentation\\Z.GenerateDocumentation.csproj ; C:\\Projects\\UsercubeV5\\Debug\\Z.GenerateDocumentation.exe\nThen you use GitExtension to commit and push the changes.\n"},{"id":9,"href":"/","title":"Geekdocs","parent":"","content":""},{"id":10,"href":"/posts/","title":"Posts","parent":"Geekdocs","content":""},{"id":11,"href":"/tags/","title":"Tags","parent":"Geekdocs","content":""}]